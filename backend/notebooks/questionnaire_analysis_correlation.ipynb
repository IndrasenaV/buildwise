{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire to Analysis Correlation Experiment\n",
    "\n",
    "This notebook demonstrates how to correlate **Homeowner Interview Answers** with **Architecture Analysis** to generate personalized, high-value suggestions.\n",
    "\n",
    "## Goal\n",
    "Prove that explicitly instructing the LLM to cross-reference interview answers results in better, context-aware suggestions compared to a baseline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 1. Setup & Auth\n",
    "# Load .env from backend root\n",
    "env_path = Path(\"../.env\")\n",
    "if not env_path.exists():\n",
    "    env_path = Path(\"../../.env\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"WARNING: OPENAI_API_KEY not found. Please ensure .env is set.\")\n",
    "else:\n",
    "    print(\"Environment loaded. Ready to run.\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mock Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Mock Architecture Context (Simulating what we extracted from a plan)\n",
    "mock_plan_context = \"\"\"\n",
    "Project Address: 123 Maple Dr, Austin, TX\n",
    "Total SqFt: 2800\n",
    "House Type: Single Family\n",
    "Exterior: Stucco with large glass windows on West facing facade.\n",
    "Roof: Flat roof, TPO membrane.\n",
    "Rooms:\n",
    "- Master Bed: 18x16, large windows facing street.\n",
    "- Home Office: 10x12, adjacent to Kitchen, sliding barn door.\n",
    "- Kitchen: Open concept, large island.\n",
    "\"\"\"\n",
    "\n",
    "# B. Mock Interview Answers (The user's specific constraints)\n",
    "mock_answers = {\n",
    "    \"privacy_concern\": \"High. We value privacy significantly and do not want street visibility.\",\n",
    "    \"noise_sensitivity\": \"Very Sensitive. Use the home office for recording, need silence.\",\n",
    "    \"budget_tier\": \"Economy. We want to save money where possible.\",\n",
    "    \"natural_light\": \"Love natural light, but hate glare.\"\n",
    "}\n",
    "\n",
    "print(\"Mock Data Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Analysis (Current State)\n",
    "Analyzes the plan *without* explicit reference to the interview answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_system_prompt = \"\"\"\n",
    "You are Buildwise AI. Analyze the provided architectural context and return a JSON object with a list of 'suggestions' for improvements.\n",
    "Focus on standard architectural best practices.\n",
    "Output JSON format: { \"suggestions\": [\"string\"] }\n",
    "\"\"\"\n",
    "\n",
    "baseline_messages = [\n",
    "    SystemMessage(content=baseline_system_prompt),\n",
    "    HumanMessage(content=f\"Architecture Context:\\n{mock_plan_context}\")\n",
    "]\n",
    "\n",
    "print(\"Running Baseline Analysis...\")\n",
    "baseline_res = llm.invoke(baseline_messages)\n",
    "try:\n",
    "    baseline_data = json.loads(baseline_res.content)\n",
    "    print(\"\\n--- Baseline Suggestions ---\")\n",
    "    for s in baseline_data.get(\"suggestions\", []):\n",
    "        print(f\"- {s}\")\n",
    "except Exception as e:\n",
    "    print(\"Error parsing baseline:\", e)\n",
    "    print(baseline_res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlated Analysis (Proposed State)\n",
    "Analyzes the plan *with* the interview answers and an updated prompt instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_system_prompt = \"\"\"\n",
    "You are Buildwise AI. Analyze the architectural context to provide personalized layout and material suggestions.\n",
    "\n",
    "CRITICAL INSTRUCTION:\n",
    "You have access to 'Homeowner Interview Answers'. You MUST cross-reference these answers with the floor plan features.\n",
    "For every suggestion, if it relates to a user answer, explicitly mention *why* based on their answer.\n",
    "\n",
    "Output JSON format:\n",
    "{\n",
    "  \"suggestions\": [\"string\"],\n",
    "  \"correlated_suggestions\": [\n",
    "    { \"suggestion\": \"string\", \"reasoning\": \"string referencing specific user answer\" }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "user_input = f\"\"\"\n",
    "Architecture Context:\n",
    "{mock_plan_context}\n",
    "\n",
    "Homeowner Interview Answers:\n",
    "{json.dumps(mock_answers, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "correlated_messages = [\n",
    "    SystemMessage(content=correlated_system_prompt),\n",
    "    HumanMessage(content=user_input)\n",
    "]\n",
    "\n",
    "print(\"Running Correlated Analysis...\")\n",
    "correlated_res = llm.invoke(correlated_messages)\n",
    "try:\n",
    "    correlated_data = json.loads(correlated_res.content)\n",
    "    \n",
    "    print(\"\\n--- Correlated Suggestions (Personalized) ---\")\n",
    "    for item in correlated_data.get(\"correlated_suggestions\", []):\n",
    "        print(f\"Suggestion: {item['suggestion']}\")\n",
    "        print(f\"  -> Why: {item['reasoning']}\")\n",
    "        print(\"-\")\n",
    "        \n",
    "    print(\"\\n--- General Suggestions ---\")\n",
    "    for s in correlated_data.get(\"suggestions\", []):\n",
    "        print(f\"- {s}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error parsing correlated:\", e)\n",
    "    print(correlated_res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "Compare the \"Baseline\" vs \"Correlated\" output above.\n",
    "\n",
    "**Expected Outcome:**\n",
    "- **Baseline**: Might suggest generic things like \"Consider energy efficient windows\".\n",
    "- **Correlated**: Should specifically say \"Install clerestory windows or privacy film in Master Bed because you mentioned high privacy concern\" or \"Add solid core door and sound insulation to Home Office due to noise sensitivity for recording\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
